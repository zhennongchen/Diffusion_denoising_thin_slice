{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/host/d/Github')\n",
    "import nibabel as nb\n",
    "import glob\n",
    "import os\n",
    "import glob\n",
    "import lpips\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "import Diffusion_denoising_thin_slice.functions_collection as ff\n",
    "import Diffusion_denoising_thin_slice.Build_lists.Build_list as Build_list\n",
    "import Diffusion_denoising_thin_slice.Data_processing as Data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_sheet =  Build_list.Build_thinsliceCT(os.path.join('/host/d/Data/brain_CT/Patient_lists/fixedCT_static_simulation_train_test_gaussian_xjtlu.xlsx'))\n",
    "_,patient_id_list,patient_subid_list,random_num_list, condition_list, x0_list = build_sheet.__build__(batch_list = [5]) \n",
    "n = ff.get_X_numbers_in_interval(total_number = patient_id_list.shape[0],start_number = 0,end_number = 1, interval = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae_with_ref_window(img, ref, vmin, vmax):\n",
    "    maes = []\n",
    "    for slice_num in range(0, img.shape[-1]):\n",
    "        slice_img = img[:,:,slice_num]\n",
    "        slice_ref = ref[:,:,slice_num]\n",
    "        mask = np.where((slice_ref >= vmin) & (slice_ref <= vmax), 1, 0)\n",
    "        mae = np.sum(np.abs(slice_img - slice_ref) * mask) / np.sum(mask)\n",
    "        maes.append(mae)\n",
    "\n",
    "    return np.mean(maes), np.std(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ssim_with_ref_window(img, ref, vmin, vmax):\n",
    "\n",
    "    ssims = []\n",
    "    for slice_num in range(0, img.shape[-1]):\n",
    "        slice_img = img[:,:,slice_num]\n",
    "        slice_ref = ref[:,:,slice_num]\n",
    "        mask = np.where((slice_ref >= vmin) & (slice_ref <= vmax), 1, 0)\n",
    "        _, ssim_map = structural_similarity(slice_img, slice_ref, data_range=vmax - vmin, full=True)\n",
    "        ssim = np.sum(ssim_map * mask) / np.sum(mask)\n",
    "        ssims.append(ssim)\n",
    "\n",
    "    return np.mean(ssims), np.std(ssims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lpips(imgs1, imgs2, vmin, vmax):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    loss_fn = lpips.LPIPS().to(device)\n",
    "    \n",
    "    lpipss = []\n",
    "    for slice_num in range(0, imgs1.shape[-1]):\n",
    "        slice1 = imgs1[:,:,slice_num]\n",
    "        slice2 = imgs2[:,:,slice_num]\n",
    "\n",
    "        slice1 = np.clip(slice1, vmin, vmax).astype(np.float32)\n",
    "        slice2 = np.clip(slice2, vmin, vmax).astype(np.float32)\n",
    "\n",
    "        slice1 = (slice1 - vmin) / (vmax - vmin) * 2 - 1\n",
    "        slice2 = (slice2 - vmin) / (vmax - vmin) * 2 - 1\n",
    "\n",
    "        slice1 = np.stack([slice1, slice1, slice1], axis=-1)\n",
    "        slice2 = np.stack([slice2, slice2, slice2], axis=-1)\n",
    "        # print('after stack, slice1 shape:', slice1.shape, ' slice2 shape:', slice2.shape)\n",
    "\n",
    "        slice1 = np.transpose(slice1, (2, 0, 1))[np.newaxis, ...]\n",
    "        slice2 = np.transpose(slice2, (2, 0, 1))[np.newaxis, ...]\n",
    "        # print('after transpose, slice1 shape:', slice1.shape, ' slice2 shape:', slice2.shape)\n",
    "\n",
    "        slice1 = torch.from_numpy(slice1).to(device)\n",
    "        slice2 = torch.from_numpy(slice2).to(device)\n",
    "\n",
    "        lpips_val = loss_fn(slice1, slice2)\n",
    "        lpipss.append(lpips_val.item())\n",
    "\n",
    "      \n",
    "\n",
    "    return np.mean(lpipss), np.std(lpipss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postprocess noise2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for i in range(0,n.shape[0]):\n",
    "#     patient_id = patient_id_list[n[i]]\n",
    "#     patient_subid = patient_subid_list[n[i]]\n",
    "#     random_n = random_num_list[n[i]]\n",
    "#     print(patient_id, patient_subid, random_n)\n",
    "\n",
    "#     # reference image\n",
    "#     gt_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/gt_img.nii.gz')\n",
    "#     gt_img = nb.load(gt_file).get_fdata()\n",
    "\n",
    "#     # noisy image\n",
    "#     condition_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/condition_img.nii.gz')\n",
    "#     condition_img = nb.load(condition_file).get_fdata()\n",
    "\n",
    "#     # noise2noise\n",
    "#     noise2noise_file = os.path.join('/host/d/projects/denoising/models/noise2noise_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch78/pred_img.nii.gz')\n",
    "#     noise2noise_img = nb.load(noise2noise_file).get_fdata() \n",
    "\n",
    "#     # noise2score\n",
    "#     noise2score_file = os.path.join('/host/d/projects/denoising/models/noise2score_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch100/pred_img.nii.gz')\n",
    "#     noise2score_img = nb.load(noise2score_file).get_fdata()\n",
    "\n",
    "#     ## calculate main\n",
    "#     x,y = 256,256\n",
    "#     mean_gt = np.mean(np.clip(gt_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "#     mean_condition = np.mean(np.clip(condition_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "#     mean_noise2noise = np.mean(np.clip(noise2noise_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "#     mean_noise2score = np.mean(np.clip(noise2score_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "\n",
    "#     print('mean: gt:', mean_gt, ' condition:', mean_condition, ' noise2noise:', mean_noise2noise, ' noise2score:', mean_noise2score)\n",
    "\n",
    "#     delta = mean_noise2noise - mean_noise2score\n",
    "\n",
    "#     noise2score_img += delta\n",
    "#     affine = nb.load(noise2score_file).affine\n",
    "#     nb.save(nb.Nifti1Image(noise2score_img, affine), os.path.join('/host/d/projects/denoising/models/noise2score_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch100/pred_img_postprocess.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00019591 0000455445 0\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "condition:  6.3761041569778785 0.3960709822064643 0.14154353231191635\n",
      "noise2noise:  3.770160209649059 0.7009809220511145 0.08679238811135292\n",
      "noise2score:  5.040073857783898 0.6340343228161661 0.0938999493420124\n",
      "ddm2_first:  2.668983437194707 0.7899129782241452 0.04520777806639671\n",
      "ddm2_final:  2.9088326629412933 0.7823989720764127 0.04501012243330479\n",
      "supervised:  3.4002701287853454 0.6151455989205552 0.06240621916949749\n",
      "unsupervised:  5.61848983193352 0.3745259893096739 0.12470711246132851\n",
      "unsupervised_avg10:  2.91622943419085 0.6744641895654975 0.04212107136845589\n",
      "unsupervised_avg20:  2.68484798551756 0.716944047662409 0.03887475438416004\n",
      "distilled:  2.820167806595066 0.7434042614378983 0.057346446886658665\n",
      "00010461 0000455845 0\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "condition:  6.43744125553988 0.3944770089938624 0.10271216928958893\n",
      "noise2noise:  4.260620684628248 0.619341329238842 0.06616340845823288\n",
      "noise2score:  4.915634245349073 0.6174067488472745 0.0692403021454811\n",
      "ddm2_first:  2.663280566542025 0.7878958456276273 0.030024971663951874\n",
      "ddm2_final:  3.276235456392286 0.7386955810313885 0.03853642541915178\n",
      "supervised:  3.3228872805587484 0.6408007271453241 0.045653958395123484\n",
      "unsupervised:  5.541322192709727 0.39606818235464003 0.08904828473925591\n",
      "unsupervised_avg10:  2.9256924760669905 0.6861269271211965 0.034525436833500865\n",
      "unsupervised_avg20:  2.697780061406393 0.7296044185697201 0.031088127419352532\n",
      "distilled:  2.980527153527597 0.7512374657863401 0.045783331990242\n",
      "00014689 0000455416 0\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /opt/conda/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "condition:  6.705985863370074 0.36483990885290574 0.1620174217224121\n",
      "noise2noise:  4.018281877045435 0.661798083360146 0.11736852869391441\n",
      "noise2score:  3.967194343812374 0.6771942214318265 0.09344840988516807\n",
      "ddm2_first:  2.7502255800297637 0.7334653097717725 0.06572278089821339\n",
      "ddm2_final:  3.3837430325128555 0.6844494064719171 0.07430193983018399\n",
      "supervised:  2.959931736088068 0.7017359468128204 0.05583627000451088\n",
      "unsupervised:  5.520103383401314 0.3969938397213478 0.12842388167977334\n",
      "unsupervised_avg10:  2.7903551698953093 0.7026291141109455 0.046864577904343604\n",
      "unsupervised_avg20:  2.5421091768426827 0.75267153903162 0.0371755537763238\n",
      "distilled:  2.8750502874600783 0.7806706877073678 0.04880617097020149\n"
     ]
    }
   ],
   "source": [
    "## metric calculations\n",
    "from genericpath import isfile\n",
    "import shutil\n",
    "\n",
    "results = []\n",
    "save_collection = True\n",
    "for i in range(0,n.shape[0]):\n",
    "    patient_id = patient_id_list[n[i]]\n",
    "    patient_subid = patient_subid_list[n[i]]\n",
    "    random_n = random_num_list[n[i]]\n",
    "\n",
    "    print(patient_id, patient_subid, random_n)\n",
    "\n",
    "    save_folder = os.path.join('/host/d/projects/denoising/models/pred_collections/brain_CT', patient_id, patient_subid)\n",
    "    ff.make_folder([os.path.dirname(save_folder), save_folder])\n",
    "\n",
    "    # reference image\n",
    "    gt_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/gt_img.nii.gz')\n",
    "    gt_img = nb.load(gt_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(gt_file, os.path.join(save_folder, 'gt_img.nii.gz'))\n",
    "\n",
    "    # noisy image\n",
    "    condition_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/condition_img.nii.gz')\n",
    "    condition_img = nb.load(condition_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(condition_file, os.path.join(save_folder, 'condition_img.nii.gz'))\n",
    "\n",
    "    # noise2noise\n",
    "    noise2noise_file = os.path.join('/host/d/projects/denoising/models/noise2noise_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch78/pred_img.nii.gz')\n",
    "    noise2noise_img = nb.load(noise2noise_file).get_fdata() \n",
    "    if save_collection:\n",
    "        shutil.copy(noise2noise_file, os.path.join(save_folder, 'noise2noise_img.nii.gz'))\n",
    "\n",
    "    # noise2score\n",
    "    noise2score_file = os.path.join('/host/d/projects/denoising/models/noise2score_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch100/pred_img_postprocess.nii.gz')\n",
    "    noise2score_img = nb.load(noise2score_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(noise2score_file, os.path.join(save_folder, 'noise2score_img.nii.gz'))\n",
    "\n",
    "    # DDM2_firststep\n",
    "    ddm2_first_file = os.path.join('/host/d/projects/denoising/models/DDM2_brainCT/pred_images', patient_id, patient_subid,'ddm2_first_step.nii.gz')\n",
    "    ddm2_first_img = nb.load(ddm2_first_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(ddm2_first_file, os.path.join(save_folder, 'ddm2_firststep_img.nii.gz'))\n",
    "\n",
    "    # DDM2_finalstep\n",
    "    ddm2_final_file = os.path.join('/host/d/projects/denoising/models/DDM2_brainCT/pred_images', patient_id, patient_subid,'ddm2_final.nii.gz')\n",
    "    ddm2_final_img = nb.load(ddm2_final_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(ddm2_final_file, os.path.join(save_folder, 'ddm2_finalstep_img.nii.gz'))\n",
    "\n",
    "    # supervised method\n",
    "    supervised_file = os.path.join('/host/d/projects/denoising/models/supervised_poisson_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch58_1/pred_img.nii.gz')\n",
    "    supervised_img = nb.load(supervised_file).get_fdata() \n",
    "    if save_collection:\n",
    "        shutil.copy(supervised_file, os.path.join(save_folder, 'supervised_img.nii.gz'))\n",
    "\n",
    "    # our method (unsupervised), 1 inference\n",
    "    unsupervised_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/pred_img.nii.gz')\n",
    "    unsupervised_img = nb.load(unsupervised_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(unsupervised_file, os.path.join(save_folder, 'unsupervised_img.nii.gz'))\n",
    "\n",
    "    # our method (unsupervised), 10 inference\n",
    "    unsupervised_avg10_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61avg/pred_img_scans10.nii.gz')\n",
    "    unsupervised_avg10_img = nb.load(unsupervised_avg10_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(unsupervised_avg10_file, os.path.join(save_folder, 'unsupervised_avg10_img.nii.gz'))\n",
    "\n",
    "    # our method (unsupervised), beta = 0, 20 inference\n",
    "    unsupervised_avg20_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61avg/pred_img_scans20.nii.gz')\n",
    "    unsupervised_avg20_img = nb.load(unsupervised_avg20_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(unsupervised_avg20_file, os.path.join(save_folder, 'unsupervised_avg20_img.nii.gz'))\n",
    "\n",
    "    # our method (distilled DDPM)\n",
    "    distilled_file = os.path.join('/host/d/projects/denoising/models/distill_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch164_1/pred_img.nii.gz')\n",
    "    distilled_img = nb.load(distilled_file).get_fdata()\n",
    "    if save_collection:\n",
    "        shutil.copy(distilled_file, os.path.join(save_folder, 'distilled_img.nii.gz'))\n",
    "\n",
    "\n",
    "    ## calculate metrics\n",
    "    # MAE\n",
    "    vmin = 0\n",
    "    vmax = 100\n",
    "    mae_condition, mae_condition_std = calc_mae_with_ref_window(condition_img, gt_img, vmin, vmax)\n",
    "    mae_noise2noise, mae_noise2noise_std = calc_mae_with_ref_window(noise2noise_img, gt_img, vmin, vmax)\n",
    "    mae_noise2score, mae_noise2score_std = calc_mae_with_ref_window(noise2score_img, gt_img, vmin, vmax)\n",
    "    mae_ddm2_first, mae_ddm2_first_std = calc_mae_with_ref_window(ddm2_first_img, gt_img, vmin, vmax)\n",
    "    mae_ddm2_final, mae_ddm2_final_std = calc_mae_with_ref_window(ddm2_final_img, gt_img, vmin, vmax)\n",
    "    mae_supervised, mae_supervised_std = calc_mae_with_ref_window(supervised_img, gt_img, vmin, vmax)\n",
    "    mae_unsupervised, mae_unsupervised_std = calc_mae_with_ref_window(unsupervised_img, gt_img, vmin, vmax)\n",
    "    mae_unsupervised_avg10, mae_unsupervised_avg10_std = calc_mae_with_ref_window(unsupervised_avg10_img, gt_img, vmin, vmax)\n",
    "    mae_unsupervised_avg20, mae_unsupervised_avg20_std = calc_mae_with_ref_window(unsupervised_avg20_img, gt_img, vmin, vmax)\n",
    "    mae_distilled, mae_distilled_std = calc_mae_with_ref_window(distilled_img, gt_img, vmin, vmax)\n",
    "   \n",
    "    \n",
    "    # # SSIM\n",
    "    ssim_condition, ssim_condition_std = calc_ssim_with_ref_window(condition_img, gt_img, vmin, vmax)\n",
    "    ssim_noise2noise, ssim_noise2noise_std = calc_ssim_with_ref_window(noise2noise_img, gt_img, vmin, vmax)\n",
    "    ssim_noise2score, ssim_noise2score_std = calc_ssim_with_ref_window(noise2score_img, gt_img, vmin, vmax)\n",
    "    ssim_ddm2_first, ssim_ddm2_first_std = calc_ssim_with_ref_window(ddm2_first_img, gt_img, vmin, vmax)\n",
    "    ssim_ddm2_final, ssim_ddm2_final_std = calc_ssim_with_ref_window(ddm2_final_img, gt_img, vmin, vmax)\n",
    "    ssim_supervised, ssim_supervised_std = calc_ssim_with_ref_window(supervised_img, gt_img, vmin, vmax)\n",
    "    ssim_unsupervised, ssim_unsupervised_std = calc_ssim_with_ref_window(unsupervised_img, gt_img, vmin, vmax)\n",
    "    ssim_unsupervised_avg10, ssim_unsupervised_avg10_std = calc_ssim_with_ref_window(unsupervised_avg10_img, gt_img, vmin, vmax)\n",
    "    ssim_unsupervised_avg20, ssim_unsupervised_avg20_std = calc_ssim_with_ref_window(unsupervised_avg20_img, gt_img, vmin, vmax)\n",
    "    ssim_distilled, ssim_distilled_std = calc_ssim_with_ref_window(distilled_img, gt_img, vmin, vmax)\n",
    "    \n",
    "\n",
    "    # # lpips\n",
    "    lpips_condition, _ = calc_lpips(condition_img, gt_img, vmin, vmax)\n",
    "    lpips_noise2noise, _ = calc_lpips(noise2noise_img, gt_img, vmin, vmax)\n",
    "    lpips_noise2score, _ = calc_lpips(noise2score_img, gt_img, vmin, vmax)\n",
    "    lpips_ddm2_first, _ = calc_lpips(ddm2_first_img, gt_img, vmin, vmax)\n",
    "    lpips_ddm2_final, _ = calc_lpips(ddm2_final_img, gt_img, vmin, vmax)\n",
    "    lpips_supervised, _ = calc_lpips(supervised_img, gt_img, vmin, vmax)\n",
    "    lpips_unsupervised, _ = calc_lpips(unsupervised_img, gt_img, vmin, vmax)\n",
    "    lpips_unsupervised_avg10, _ = calc_lpips(unsupervised_avg10_img, gt_img, vmin, vmax)\n",
    "    lpips_unsupervised_avg20, _ = calc_lpips(unsupervised_avg20_img, gt_img, vmin, vmax)\n",
    "    lpips_distilled, _ = calc_lpips(distilled_img, gt_img, vmin, vmax)\n",
    "\n",
    "    print('condition: ', mae_condition, ssim_condition, lpips_condition)\n",
    "    print('noise2noise: ', mae_noise2noise, ssim_noise2noise, lpips_noise2noise)\n",
    "    print('noise2score: ', mae_noise2score, ssim_noise2score, lpips_noise2score)\n",
    "    print('ddm2_first: ', mae_ddm2_first, ssim_ddm2_first, lpips_ddm2_first)\n",
    "    print('ddm2_final: ', mae_ddm2_final, ssim_ddm2_final, lpips_ddm2_final)\n",
    "    print('supervised: ', mae_supervised, ssim_supervised, lpips_supervised)\n",
    "    print('unsupervised: ', mae_unsupervised, ssim_unsupervised, lpips_unsupervised)\n",
    "    print('unsupervised_avg10: ', mae_unsupervised_avg10, ssim_unsupervised_avg10, lpips_unsupervised_avg10)\n",
    "    print('unsupervised_avg20: ', mae_unsupervised_avg20, ssim_unsupervised_avg20, lpips_unsupervised_avg20)\n",
    "    print('distilled: ', mae_distilled, ssim_distilled, lpips_distilled)\n",
    "\n",
    "    results.append([patient_id, patient_subid, random_n,\n",
    "                    mae_condition,mae_noise2noise,mae_noise2score,mae_ddm2_first, mae_ddm2_final, mae_supervised, mae_unsupervised, mae_unsupervised_avg10, mae_unsupervised_avg20, mae_distilled,\n",
    "                    ssim_condition,ssim_noise2noise,ssim_noise2score,ssim_ddm2_first, ssim_ddm2_final, ssim_supervised, ssim_unsupervised, ssim_unsupervised_avg10, ssim_unsupervised_avg20, ssim_distilled,\n",
    "                    lpips_condition,lpips_noise2noise,lpips_noise2score,lpips_ddm2_first, lpips_ddm2_final, lpips_supervised, lpips_unsupervised, lpips_unsupervised_avg10, lpips_unsupervised_avg20, lpips_distilled\n",
    "                    ])\n",
    "\n",
    "    dd = pd.DataFrame(results, columns = ['patient_id','patient_subid','random_n',\n",
    "    'mae_condition','mae_noise2noise','mae_noise2score','mae_ddm2_first','mae_ddm2_final','mae_supervised','mae_unsupervised','mae_unsupervised_avg10','mae_unsupervised_avg20','mae_distilled',\n",
    "    'ssim_condition','ssim_noise2noise','ssim_noise2score','ssim_ddm2_first','ssim_ddm2_final','ssim_supervised','ssim_unsupervised','ssim_unsupervised_avg10','ssim_unsupervised_avg20','ssim_distilled',\n",
    "    'lpips_condition','lpips_noise2noise','lpips_noise2score','lpips_ddm2_first','lpips_ddm2_final','lpips_supervised','lpips_unsupervised','lpips_unsupervised_avg10','lpips_unsupervised_avg20','lpips_distilled'\n",
    "    ])  \n",
    "    dd.to_excel('/host/d/projects/denoising/results/brainCT_results.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00214841 0000455418 0\n",
      "mean: gt: 21.754015723196854  condition: 21.89032840789795  noise2noise: 19.03606891879365  noise2score: 15.506743506469727\n",
      "00105734 0000455323 0\n",
      "mean: gt: 18.486178371301225  condition: 18.97817980621338  noise2noise: 14.566930114135912  noise2score: 14.303804944152832\n",
      "00214867 0000455521 0\n",
      "mean: gt: 32.106963860106056  condition: 32.13290597808838  noise2noise: 30.043341023751566  noise2score: 25.375424999389647\n",
      "00214877 0000455524 0\n",
      "mean: gt: 31.27295554296927  condition: 31.359965008850097  noise2noise: 28.43605288487233  noise2score: 25.188118078308104\n",
      "00214836 0000455414 0\n",
      "mean: gt: 15.307165243522553  condition: 15.87778719329834  noise2noise: 11.581240975344958  noise2score: 9.508770465698243\n",
      "00154137 0000455529 0\n",
      "mean: gt: 32.78842260734797  condition: 32.843813273010255  noise2noise: 29.875630303859552  noise2score: 26.09790611022949\n",
      "00214901 0000455577 0\n",
      "mean: gt: 25.038895094831215  condition: 25.23733533203125  noise2noise: 21.86812425697546  noise2score: 20.032635048828126\n",
      "00174234 0000455725 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# noise2score\u001b[39;00m\n\u001b[1;32m     23\u001b[0m noise2score_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/host/d/projects/denoising/models/noise2score_brainCT/pred_images\u001b[39m\u001b[38;5;124m'\u001b[39m, patient_id, patient_subid,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(random_n), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch100/pred_img.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m noise2score_img \u001b[38;5;241m=\u001b[39m \u001b[43mnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise2score_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m## calculate main\u001b[39;00m\n\u001b[1;32m     29\u001b[0m x,y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nibabel/dataobj_images.py:373\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nibabel/arrayproxy.py:439\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nibabel/arrayproxy.py:406\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    404\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nibabel/arrayproxy.py:376\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[1;32m    373\u001b[0m     (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    374\u001b[0m ):\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 376\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[1;32m    386\u001b[0m         fileobj,\n\u001b[1;32m    387\u001b[0m         slicer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m         lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock,\n\u001b[1;32m    393\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nibabel/volumeutils.py:465\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    464\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[0;32m--> 465\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/_compression.py:69\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m     68\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m(byte_view))\n\u001b[0;32m---> 69\u001b[0m     byte_view[:\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate mean\n",
    "## metric calculations\n",
    "results = []\n",
    "for i in range(0,n.shape[0]):\n",
    "    patient_id = patient_id_list[n[i]]\n",
    "    patient_subid = patient_subid_list[n[i]]\n",
    "    random_n = random_num_list[n[i]]\n",
    "    print(patient_id, patient_subid, random_n)\n",
    "\n",
    "    # reference image\n",
    "    gt_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/gt_img.nii.gz')\n",
    "    gt_img = nb.load(gt_file).get_fdata()\n",
    "\n",
    "    # noisy image\n",
    "    condition_file = os.path.join('/host/d/projects/denoising/models/unsupervised_gaussian_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch61_1/condition_img.nii.gz')\n",
    "    condition_img = nb.load(condition_file).get_fdata()\n",
    "\n",
    "    # noise2noise\n",
    "    noise2noise_file = os.path.join('/host/d/projects/denoising/models/noise2noise_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch78/pred_img.nii.gz')\n",
    "    noise2noise_img = nb.load(noise2noise_file).get_fdata() \n",
    "\n",
    "    # noise2score\n",
    "    noise2score_file = os.path.join('/host/d/projects/denoising/models/noise2score_brainCT/pred_images', patient_id, patient_subid,'random_'+str(random_n), 'epoch100/pred_img.nii.gz')\n",
    "    noise2score_img = nb.load(noise2score_file).get_fdata()\n",
    "\n",
    "\n",
    "    ## calculate main\n",
    "    x,y = 256,256\n",
    "    mean_gt = np.mean(np.clip(gt_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "    mean_condition = np.mean(np.clip(condition_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "    mean_noise2noise = np.mean(np.clip(noise2noise_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "    mean_noise2score = np.mean(np.clip(noise2score_img[x-50: x+50, y-50: y+50, 20:40],0,100))\n",
    "\n",
    "    print('mean: gt:', mean_gt, ' condition:', mean_condition, ' noise2noise:', mean_noise2noise, ' noise2score:', mean_noise2score)\n",
    "    \n",
    "    results.append([patient_id, patient_subid, random_n,\n",
    "                    mean_gt, mean_condition, mean_noise2noise, mean_noise2score\n",
    "                    ])\n",
    "    dd = pd.DataFrame(results, columns = ['patient_id','patient_subid','random_n',\n",
    "                                             'mean_gt','mean_condition','mean_noise2noise','mean_noise2score'\n",
    "                                             ])\n",
    "\n",
    "    dd.to_excel('/host/d/projects/denoising/results/brainCT_mean_results.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
